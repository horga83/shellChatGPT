<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="mountaineerbr" />
  <title>CHATGPT.SH(1) v0.11.7 | General Commands Manual</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">CHATGPT.SH(1) v0.11.7 | General Commands Manual</h1>
<p class="author">mountaineerbr</p>
<p class="date">April 2023</p>
</header>
<h3 id="name">NAME</h3>
<div class="line-block">   chatgpt.sh – ChatGPT / DALL-E / Whisper Shell
Wrapper</div>
<h3 id="synopsis">SYNOPSIS</h3>
<div class="line-block">   <strong>chatgpt.sh</strong> [<code>-m</code>
[<em>MODEL_NAME</em>|<em>MODEL_INDEX</em>]] [<code>opt</code>]
[<em>PROMPT|TXT_FILE</em>]<br />
   <strong>chatgpt.sh</strong> [<code>-m</code>
[<em>MODEL_NAME</em>|<em>MODEL_INDEX</em>]] [<code>opt</code>]
[<em>INSTRUCTION</em>] [<em>INPUT</em>]<br />
   <strong>chatgpt.sh</strong> <code>-e</code> [<code>opt</code>]
[<em>INSTRUCTION</em>] [<em>INPUT</em>]<br />
   <strong>chatgpt.sh</strong> <code>-i</code> [<code>opt</code>]
[<em>S</em>|<em>M</em>|<em>L</em>] [<em>PROMPT</em>]<br />
   <strong>chatgpt.sh</strong> <code>-i</code> [<code>opt</code>]
[<em>S</em>|<em>M</em>|<em>L</em>] [<em>PNG_FILE</em>]<br />
   <strong>chatgpt.sh</strong> <code>-i</code> [<code>opt</code>]
[<em>S</em>|<em>M</em>|<em>L</em>] [<em>PNG_FILE</em>]
[<em>MASK_FILE</em>] [<em>PROPMT</em>]<br />
   <strong>chatgpt.sh</strong> <code>-w</code> [<code>opt</code>]
[<em>AUDIO_FILE</em>] [<em>LANG</em>] [<em>PROMPT-LANG</em>]<br />
   <strong>chatgpt.sh</strong> <code>-W</code> [<code>opt</code>]
[<em>AUDIO_FILE</em>] [<em>PROMPT-EN</em>]<br />
   <strong>chatgpt.sh</strong> <code>-ccw</code> [<code>opt</code>]
[<em>LANG</em>]<br />
   <strong>chatgpt.sh</strong> <code>-ccW</code>
[<code>opt</code>]<br />
   <strong>chatgpt.sh</strong> <code>-l</code>
[<em>MODEL_NAME</em>]</div>
<h3 id="description">DESCRIPTION</h3>
<p>All positional arguments are read as a single
<strong>PROMPT</strong>. If the chosen model requires an
<strong>INSTRUCTION</strong> and <strong>INPUT prompts</strong>, the
first positional argument is taken as INSTRUCTION and the following ones
as INPUT or PROMPT.</p>
<p>Set <code>option -c</code> to start the chat mode via the
<strong>text completions</strong> and record the conversation. This
option accepts various models, defaults to <em>text-davinci-003</em> if
none set.</p>
<p>Set <code>option -cc</code> to start the chat mode via <strong>native
chat completions</strong> and use the turbo models. While in chat mode,
some options are automatically set to un-lobotomise the bot.</p>
<p>Set <code>-C</code> to <strong>resume</strong> from last history
session. Setting <code>-CC</code> starts a <strong>new session</strong>
in the history file (without <code>-c</code> or <code>-cc</code>).</p>
<p>Set model with “<code>-m</code> [<em>NAME</em>]” (full model name).
Some models have an equivalent <em>INDEX</em> as short-hand, so
“<code>-m</code><em>text-davinci-003</em>” and
“<code>-m</code><em>0</em>” set the same model (list model by
<em>NAME</em> with <code>option -l</code> or by <em>INDEX</em> with
<code>option -ll</code>).</p>
<p>Set <em>maximum response tokens</em> with <code>option</code>
“<code>-</code>NUM” or “<code>-M</code> NUM”. This defaults to 256
tokens in chat and single-turn modes.</p>
<p><em>Maximum model tokens</em> can be set with a second <em>NUM</em>
such as “<code>-</code><em>NUM,NUM</em>” or “<code>-M</code> NUM-NUM”,
otherwise it is set automatically to the capacity of known models, or to
<em>2048</em> tokens as fallback.</p>
<p>If a plain text file path is set as first positional argument, it is
loaded as text PROMPT (text cmpls, chat cmpls, and text/code edits).</p>
<p><code>Option -S</code> sets an INSTRUCTION prompt (the initial
prompt) for text cmpls, chat cmpls, and text/code edits. A text file
path may be supplied as the single argument. If the argument to this
option starts with a backslash such as “<code>-S</code>
_/_linux_terminal”, start search for an awesome-chatgpt-prompts (by
Fatih KA).</p>
<p><code>Option -e</code> sets the <strong>text edits</strong> endpoint.
That endpoint requires both INSTRUCTION and INPUT prompts. User may
choose a model amongst the <em>edit model family</em>.</p>
<p><code>Option -i</code> <strong>generates images</strong> according to
text PROMPT. If the first positional argument is an <em>IMAGE</em> file,
then <strong>generate variations</strong> of it. If the first positional
argument is an <em>IMAGE</em> file and the second a <em>MASK</em> file
(with alpha channel and transparency), and a text PROMPT (required),
then <strong>edit the</strong> <em>IMAGE</em> according to <em>MASK</em>
and PROMPT. If <em>MASK</em> is not provided, <em>IMAGE</em> must have
transparency.</p>
<p>Optionally, size of output image may be set with
“[<em>S</em>]<em>mall</em>”, “[<em>M</em>]<em>edium</em>” or
“[<em>L</em>]<em>arge</em>” as the first positional argument. See
<strong>IMAGES section</strong> below for more information on
<strong>inpaint</strong> and <strong>outpaint</strong>.</p>
<p><code>Option -w</code> <strong>transcribes audio</strong> from
<em>mp3</em>, <em>mp4</em>, <em>mpeg</em>, <em>mpga</em>, <em>m4a</em>,
<em>wav</em>, and <em>webm</em> files. First positional argument must be
an <em>AUDIO</em> file. Optionally, set a <em>TWO-LETTER</em> input
language (<em>ISO-639-1</em>) as second argument. A PROMPT may also be
set after language (must be in the same language as the audio).</p>
<p><code>Option -W</code> <strong>translates audio</strong> stream to
<strong>English text</strong>. A PROMPT in English may be set to guide
the model as the second positional argument.</p>
<p>Combine <code>-wW</code> <strong>with</strong> <code>-cc</code> to
start <strong>chat with voice input</strong> (Whisper) support. Output
may be piped to a voice synthesiser to have a full voice in and out
experience.</p>
<p>Stdin is supported when there is no positional arguments left after
option parsing. Stdin input sets a single PROMPT.</p>
<p>User configuration is kept at “<em>~/.chatgpt.conf</em>”. Script
cache is kept at “<em>~/.cache/chatgptsh</em>”.</p>
<p>A personal (free) OpenAI API is required, set it with
<code>-K</code>. Also, see <strong>ENVIRONMENT section</strong>.</p>
<p>For complete model and settings information, refer to OpenAI API docs
at <a href="https://platform.openai.com/docs/"
class="uri">https://platform.openai.com/docs/</a>.</p>
<h3 id="text-chat-completions">TEXT / CHAT COMPLETIONS</h3>
<h4 id="text-completions">1. Text completions</h4>
<p>Given a prompt, the model will return one or more predicted
completions. For example, given a partial input, the language model will
try completing it until probable “<code>&lt;|endoftext|&gt;</code>”, or
other stop sequences (stops may be set with <code>-s</code>).</p>
<p>Language model <strong>SKILLS</strong> can activated, with specific
prompts, see <a href="https://platform.openai.com/examples"
class="uri">https://platform.openai.com/examples</a>.</p>
<p>To enable <strong>multiline input</strong>, type in a backslash
“<em>\</em>” as the last character of the input line and press ENTER
(backslash will be removed from input). Once enabled, press ENTER twice
to confirm the multiline prompt.</p>
<h4 id="chat-mode">2. Chat Mode</h4>
<h5 id="text-completions-chat">2.1 Text Completions Chat</h5>
<p>Set <code>option -c</code> to start chat mode of text completions. It
keeps a history file, and keeps new questions in context. This works
with a variety of models.</p>
<h5 id="native-chat-completions">2.2 Native Chat Completions</h5>
<p>Set the double <code>option -cc</code> to start chat completions
mode. Turbo models are also the best option for many non-chat use
cases.</p>
<h5 id="q-a-format">2.3 Q &amp; A Format</h5>
<p>The defaults chat format is “<code>Q &amp; A</code>”. So, the
<strong>restart text</strong> “<em>Q: </em>” and the <strong>start
text</strong> “<em>A:</em>” must be injected for the chat bot to work
well with text cmpls.</p>
<p>Typing only a colon “<em>:</em>” at the start of the prompt causes it
to be appended after a newline to the last prompt (answer) in text
cmpls. If this trick is used with the initial prompt in text cmpls, it
works as the <strong>INSTRUCTION</strong>. In chat cmpls, setting a
prompt with “<code>:</code>” always sets it as a <strong>SYSTEM</strong>
message.</p>
<h5 id="chat-commands">2.4 Chat Commands</h5>
<p>While in chat mode, the following commands can be typed in the new
prompt to set a new parameter:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: right;"><code>!NUM</code></td>
<td style="text-align: left;"><code>!max</code></td>
<td style="text-align: left;">Set response / model max tokens.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-a</code></td>
<td style="text-align: left;"><code>!pre</code></td>
<td style="text-align: left;">Set presence pensalty.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-A</code></td>
<td style="text-align: left;"><code>!freq</code></td>
<td style="text-align: left;">Set frequency penalty.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-c</code></td>
<td style="text-align: left;"><code>!new</code></td>
<td style="text-align: left;">Start new session.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-H</code></td>
<td style="text-align: left;"><code>!hist</code></td>
<td style="text-align: left;">Edit history in editor.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-L</code></td>
<td style="text-align: left;"><code>!log</code></td>
<td style="text-align: left;">Save to log file.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-m</code></td>
<td style="text-align: left;"><code>!mod</code></td>
<td style="text-align: left;">Set model (by index or name).</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-p</code></td>
<td style="text-align: left;"><code>!top</code></td>
<td style="text-align: left;">Set top_p.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-r</code></td>
<td style="text-align: left;"><code>!restart</code></td>
<td style="text-align: left;">Set restart sequence.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-R</code></td>
<td style="text-align: left;"><code>!start</code></td>
<td style="text-align: left;">Set start sequence.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-s</code></td>
<td style="text-align: left;"><code>!stop</code></td>
<td style="text-align: left;">Set stop sequences.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-t</code></td>
<td style="text-align: left;"><code>!temp</code></td>
<td style="text-align: left;">Set temperature.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-u</code></td>
<td style="text-align: left;"><code>!clip</code></td>
<td style="text-align: left;">Copy responses to clipboard.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-v</code></td>
<td style="text-align: left;"><code>!ver</code></td>
<td style="text-align: left;">Set/unset verbose.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>-x</code></td>
<td style="text-align: left;"><code>!ed</code></td>
<td style="text-align: left;">Set/unset text editor interface.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>-w</code></td>
<td style="text-align: left;"><code>!rec</code></td>
<td style="text-align: left;">Start audio record chat.</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><code>!r</code></td>
<td style="text-align: left;"><code>!regen</code></td>
<td style="text-align: left;">Renegerate last response.</td>
</tr>
<tr class="even">
<td style="text-align: right;"><code>!q</code></td>
<td style="text-align: left;"><code>!quit</code></td>
<td style="text-align: left;">Exit.</td>
</tr>
</tbody>
</table>
<p>Examples: “<code>!temp</code> <em>0.7</em>”,
“<code>!mod</code><em>1</em>”, and “<code>-p</code> <em>0.2</em>”. Note
that the command operator may be either “<code>!</code>”, or
“<code>/</code>”.</p>
<p>To change the chat context at run time, the history file must be
edited with “<code>!hist</code>”. Delete history entries or comment them
out with “<code>#</code>”.</p>
<h5 id="completion-preview-regeneration">2.5 Completion Preview /
Regeneration</h5>
<p>To preview a prompt completion before commiting it to history, append
a forward slash “<em>/</em>” to the prompt as the last character.
Regenerate it again or press ENTER to accept it.</p>
<p>After a response has been written to the history file,
<strong>regenerate</strong> it with command “<code>!regen</code>” or
type in a single forward slash in the new empty prompt.</p>
<h4 id="prompt-engineering-and-design">3. Prompt Engineering and
Design</h4>
<p>Unless the chat <code>options -c</code> or <code>-cc</code> are set,
<strong>NO</strong> INSTRUCTION is given to the language model (as
would, otherwise, be the initial prompt).</p>
<p>On chat mode, if no INSTRUCTION is set, a short one is given, and
some options set, such as increasing temp and presence penalty, in order
to un-lobotomise the bot. With cheap and fast models of text cmpls, such
as Curie, the best_of option may even be worth setting (to 2 or 3).</p>
<p>Prompt engineering is an art on itself. Study carefully how to craft
the best prompts to get the most out of text, code and chat compls
models.</p>
<p>Certain prompts may return empty responses. Maybe the model has
nothing to further complete input or it expects more text. Try trimming
spaces, appending a full stop/ellipsis, resetting temperature or adding
more text.</p>
<p>Prompts ending with a space character may result in lower quality
output. This is because the API already incorporates trailing spaces in
its dictionary of tokens.</p>
<p>Note that the model’s steering and capabilities require prompt
engineering to even know that it should answer the questions.</p>
<p>For more on prompt design, see:</p>
<ul>
<li><a
href="https://platform.openai.com/docs/guides/completion/prompt-design"
class="uri">https://platform.openai.com/docs/guides/completion/prompt-design</a></li>
<li><a
href="https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md"
class="uri">https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md</a></li>
</ul>
<p>See detailed info on settings for each endpoint at:</p>
<ul>
<li><a href="https://platform.openai.com/docs/"
class="uri">https://platform.openai.com/docs/</a></li>
</ul>
<h3 id="code-completions">CODE COMPLETIONS</h3>
<p>Codex models are discontinued. Use davinci or turbo models for coding
tasks.</p>
<p>Turn comments into code, complete the next line or function in
context, add code comments, and rewrite code for efficiency, amongst
other functions.</p>
<p>Start with a comment with instructions, data or code. To create
useful completions it’s helpful to think about what information a
programmer would need to perform a task.</p>
<h3 id="text-edits">TEXT EDITS</h3>
<p>This endpoint is set with models with <strong>edit</strong> in their
name or <code>option -e</code>. Editing works by setting INSTRUCTION on
how to modify a prompt and the prompt proper.</p>
<p>The edits endpoint can be used to change the tone or structure of
text, or make targeted changes like fixing spelling. Edits work well on
empty prompts, thus enabling text generation similar to the completions
endpoint.</p>
<h3 id="images-dall-e">IMAGES / DALL-E</h3>
<h4 id="image-generations">1. Image Generations</h4>
<p>An image can be created given a text prompt. A text PROMPT of the
desired image(s) is required. The maximum length is 1000 characters.</p>
<h4 id="image-variations">2. Image Variations</h4>
<p>Variations of a given <em>IMAGE</em> can be generated. The
<em>IMAGE</em> to use as the basis for the variations must be a valid
PNG file, less than 4MB and square.</p>
<h4 id="image-edits">3. Image Edits</h4>
<p>To edit an <em>IMAGE</em>, a <em>MASK</em> file may be optionally
provided. If <em>MASK</em> is not provided, <em>IMAGE</em> must have
transparency, which will be used as the mask. A text prompt is
required.</p>
<h5 id="imagemagick">3.1 ImageMagick</h5>
<p>If <strong>ImageMagick</strong> is available, input <em>IMAGE</em>
and <em>MASK</em> will be checked and processed to fit dimensions and
other requirements.</p>
<h5 id="transparent-colour-and-fuzz">3.2 Transparent Colour and
Fuzz</h5>
<p>A transparent colour must be set with
“<code>-@</code>[<em>COLOUR</em>]” to create the mask.
Defaults=<em>black</em>.</p>
<p>By defaults, the <em>COLOUR</em> must be exact. Use the
<code>fuzz option</code> to match colours that are close to the target
colour. This can be set with “<code>-@</code>[<em>VALUE%</em>]” as a
percentage of the maximum possible intensity, for example
“<code>-@</code><em>10%black</em>”.</p>
<p>See also:</p>
<ul>
<li><a href="https://imagemagick.org/script/color.php"
class="uri">https://imagemagick.org/script/color.php</a></li>
<li><a
href="https://imagemagick.org/script/command-line-options.php#fuzz"
class="uri">https://imagemagick.org/script/command-line-options.php#fuzz</a></li>
</ul>
<h5 id="mask-file-alpha-channel">3.3 Mask File / Alpha Channel</h5>
<p>An alpha channel is generated with <strong>ImageMagick</strong> from
any image with the set transparent colour (defaults to <em>black</em>).
In this way, it is easy to make a mask with any black and white image as
a template.</p>
<h5 id="in-paint-and-out-paint">3.4 In-Paint and Out-Paint</h5>
<p>In-painting is achieved setting an image with a MASK and a
prompt.</p>
<p>Out-painting can also be achieved manually with the aid of this
script. Paint a portion of the outer area of an image with
<em>alpha</em>, or a defined <em>transparent</em> <em>colour</em> which
will be used as the mask, and set the same <em>colour</em> in the script
with <code>-@</code>. Choose the best result amongst many results to
continue the out-painting process step-wise.</p>
<p>Optionally, for all image generations, variations, and edits, set
<strong>size of output image</strong> with “<em>256x256</em>”
(“<em>Small</em>”), “<em>512x512</em>” (“<em>Medium</em>”), or
“<em>1024x1024</em>” (“<em>Large</em>”) as the first positional
argument. Defaults=<em>512x512</em>.</p>
<h3 id="audio-whisper">AUDIO / WHISPER</h3>
<h4 id="transcriptions">1. Transcriptions</h4>
<p>Transcribes audio file or voice record into the input language. Set a
<em>two-letter</em> <em>ISO-639-1</em> language code (<em>en</em>,
<em>es</em>, <em>ja</em>, or <em>zh</em>) as the positional argument
following the input audio file. A prompt may also be set as last
positional parameter to help guide the model. This prompt should match
the audio language.</p>
<h4 id="translations">2. Translations</h4>
<p>Translates audio into <strong>English</strong>. An optional text to
guide the model’s style or continue a previous audio segment is optional
as last positional argument. This prompt should be in English.</p>
<p>Setting <strong>temperature</strong> has an effect, the higher the
more random.</p>
<h3 id="quoting-and-special-symbols">QUOTING AND SPECIAL SYMBOLS</h3>
<p>The special sequences (<code>\b</code>, <code>\f</code>,
<code>\n</code>, <code>\r</code>, <code>\t</code> and
<code>\uHEX</code>) are interpreted as quoted <em>backspace</em>,
<em>form feed</em>, <em>new line</em>, <em>return</em>, <em>tab</em> and
<em>unicode hex</em>. To preserve these symbols as literals instead (e.
g. <strong>Latex syntax</strong>), type in an extra backslash such as
“<code>\\theta</code>”.</p>
<h3 id="environment">ENVIRONMENT</h3>
<dl>
<dt><strong>CHATGPTRC</strong></dt>
<dd>
<p>Path to user chatgpt.sh configuration.</p>
<p>Defaults="<em>~/.chatgpt.conf</em>"</p>
</dd>
<dt><strong>INSTRUCTION</strong></dt>
<dd>
<p>Initial instruction set for the chatbot.</p>
</dd>
</dl>
<p><strong>OPENAI_API_KEY</strong></p>
<dl>
<dt><strong>OPENAI_KEY</strong></dt>
<dd>
<p>Set your personal (free) OpenAI API key.</p>
</dd>
<dt><strong>REC_CMD</strong></dt>
<dd>
<p>Audio recording command.</p>
</dd>
</dl>
<p><strong>VISUAL</strong></p>
<dl>
<dt><strong>EDITOR</strong></dt>
<dd>
<p>Text editor for external prompt editing.</p>
<p>Defaults="<em>vim</em>"</p>
</dd>
</dl>
<h3 id="bugs">BUGS</h3>
<p><code>Ksh93</code> mangles multibyte characters when re-editing input
prompt and truncates input longer than 80 chars. Workaround is to move
cursor one char and press the up arrow key.</p>
<p><code>Ksh2020</code> lacks functionality compared to
<code>Ksh83u+</code>, such as <code>read</code> with history.</p>
<p>With the exception of Davinci models, older models were designed to
be run as one-shot.</p>
<p>Instruction prompts are required for the model to even know that it
should answer questions.</p>
<p>Garbage in, garbage out. An idiot savant.</p>
<h3 id="requirements">REQUIREMENTS</h3>
<p>A free OpenAI <strong>API key</strong>. <code>Bash</code>,
<code>Ksh93u+</code>, or <code>Zsh</code>. <code>cURL</code>, and
<code>JQ</code>.</p>
<p><code>ImageMagick</code>, and
<code>Sox</code>/<code>Alsa-tools</code>/<code>FFmpeg</code> are
optionally required.</p>
<h3 id="long-options">LONG OPTIONS</h3>
<p>Long options can be set with an argument, or multiple times when
appropriate.</p>
<p>Ex: “<code>--chat</code>”, “<code>--temp</code>=<em>0.9</em>”,
“<code>--max</code>=<em>1024,128</em>”, and
“<code>--presence-penalty</code> <em>0.6</em>”.</p>
<blockquote>
<p><code>--alpha</code>, <code>--api-key</code>, <code>--best</code>,
<code>--best-of</code>, <code>--chat</code>, <code>--clipboard</code>,
<code>--clip</code>, <code>--cont</code>, <code>--continue</code>,
<code>--edit</code>, <code>--editor</code>, <code>--frequency</code>,
<code>--frequency-penalty</code>, <code>--help</code>,
<code>--hist</code>, <code>--image</code>, <code>--instruction</code>,
<code>--last</code>, <code>--list-model</code>,
<code>--list-models</code>, <code>--log</code>, <code>--log-prob</code>,
<code>--man</code>, <code>--max</code>, <code>--max-tokens</code>,
<code>--mod</code>, <code>--model</code>, <code>--no-colour</code>,
<code>--no-config</code>, <code>--presence</code>,
<code>--presence-penalty</code>, <code>--prob</code>,
<code>--raw</code>, <code>--restart-seq</code>,
<code>--restart-sequence</code>, <code>--results</code>,
<code>--resume</code>, <code>--start-seq</code>,
<code>--start-sequence</code>, <code>--stop</code>, <code>--temp</code>,
<code>--temperature</code>, <code>--top</code>, <code>--top-p</code>,
<code>--transcribe</code>, <code>--translate</code>, and
<code>--verbose</code>.</p>
</blockquote>
<h3 id="options">OPTIONS</h3>
<dl>
<dt><strong>-@</strong> [[<em>VAL%</em>]<em>COLOUR</em>]</dt>
<dd>
<p>Set transparent colour of image mask. Def=<em>black</em>.</p>
<p>Fuzz intensity can be set with [VAL%]. Def=<em>0%</em>.</p>
</dd>
</dl>
<p><strong>-NUM</strong></p>
<dl>
<dt><strong>-M</strong> [<em>NUM</em>[<em>-NUM</em>]]</dt>
<dd>
<p>Set maximum number of <code>response tokens</code>.
Def=<em>256</em>.</p>
<p>Maximum <code>model tokens</code> can be set with a second number.
Def=<em>auto-256</em>.</p>
</dd>
<dt><strong>-a</strong> [<em>VAL</em>]</dt>
<dd>
<p>Set presence penalty (cmpls/chat, -2.0 - 2.0).</p>
</dd>
<dt><strong>-A</strong> [<em>VAL</em>]</dt>
<dd>
<p>Set frequency penalty (cmpls/chat, -2.0 - 2.0).</p>
</dd>
<dt><strong>-b</strong> [<em>VAL</em>]</dt>
<dd>
<p>Set best of, must be greater than <code>opt -n</code> (cmpls).
Def=<em>1</em>.</p>
</dd>
<dt><strong>-B</strong></dt>
<dd>
<p>Print log probabilities to stderr (cmpls, 0 - 5).</p>
</dd>
<dt><strong>-c</strong></dt>
<dd>
<p>Chat mode in text completions, new session.</p>
</dd>
<dt><strong>-cc</strong></dt>
<dd>
<p>Chat mode in chat completions, new session.</p>
</dd>
<dt><strong>-C</strong></dt>
<dd>
<p>Continue from last session (compls/chat).</p>
<p>Set twice to start new session in chat mode (without -c, -cc).</p>
</dd>
<dt><strong>-e</strong> [<em>INSTRUCTION</em>] [<em>INPUT</em>]</dt>
<dd>
<p>Set Edit mode. Model def=<em>text-davinci-edit-001</em>.</p>
</dd>
<dt><strong>-f</strong></dt>
<dd>
<p>Ignore user config file and environment.</p>
</dd>
<dt><strong>-h</strong></dt>
<dd>
<p>Print this help page.</p>
</dd>
<dt><strong>-H</strong></dt>
<dd>
<p>Edit history file with text editor or pipe to stdout.</p>
</dd>
<dt><strong>-HH</strong></dt>
<dd>
<p>Pretty print last history session to stdout.</p>
</dd>
<dt><strong>-i</strong> [<em>PROMPT</em>]</dt>
<dd>
<p>Generate images given a prompt.</p>
</dd>
<dt><strong>-i</strong> [<em>PNG</em>]</dt>
<dd>
<p>Create variations of a given image.</p>
</dd>
<dt><strong>-i</strong> [<em>PNG</em>] [<em>MASK</em>]
[<em>PROMPT</em>]</dt>
<dd>
<p>Edit image with mask and prompt (required).</p>
</dd>
<dt><strong>-j</strong></dt>
<dd>
<p>Print raw JSON response (debug with -jVV).</p>
</dd>
<dt><strong>-k</strong></dt>
<dd>
<p>Disable colour output. Def=<em>auto</em>.</p>
</dd>
<dt><strong>-K</strong> [<em>KEY</em>]</dt>
<dd>
<p>Set API key (free).</p>
</dd>
<dt><strong>-l</strong> [<em>MOD</em>]</dt>
<dd>
<p>List models or print details of MODEL.</p>
<p>Set twice to print model indexes instead.</p>
</dd>
<dt><strong>-L</strong> [<em>FILEPATH</em>]</dt>
<dd>
<p>Set log file. <em>FILEPATH</em> is required.</p>
</dd>
<dt><strong>-m</strong> [<em>MOD</em>]</dt>
<dd>
<p>Set model by <em>NAME</em>.</p>
</dd>
<dt><strong>-m</strong> [<em>IND</em>]</dt>
<dd>
<p>Set model by <em>INDEX</em>:</p>
</dd>
</dl>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><strong>COMPLETIONS</strong></td>
<td><strong>EDITS</strong></td>
</tr>
<tr class="even">
<td></td>
<td><em>0</em>. text-davinci-003</td>
<td><em>8</em>. text-davinci-edit-001</td>
</tr>
<tr class="odd">
<td></td>
<td><em>1</em>. text-curie-001</td>
<td><em>9</em>. code-davinci-edit-001</td>
</tr>
<tr class="even">
<td></td>
<td><em>2</em>. text-babbage-001</td>
<td><strong>AUDIO</strong></td>
</tr>
<tr class="odd">
<td></td>
<td><em>3</em>. text-ada-001</td>
<td><em>11</em>. whisper-1</td>
</tr>
<tr class="even">
<td></td>
<td><strong>CHAT</strong></td>
<td><strong>GPT-4</strong></td>
</tr>
<tr class="odd">
<td></td>
<td><em>4</em>. gpt-3.5-turbo</td>
<td><em>12</em>. gpt-4</td>
</tr>
<tr class="even">
<td></td>
<td><strong>MODERATION</strong></td>
<td><em>13</em>. gpt-4-32k</td>
</tr>
<tr class="odd">
<td></td>
<td><em>6</em>. text-moderation-latest</td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td><em>7</em>. text-moderation-stable</td>
<td></td>
</tr>
</tbody>
</table>
<dl>
<dt><strong>-n</strong> [<em>NUM</em>]</dt>
<dd>
<p>Set number of results. Def=<em>1</em>.</p>
</dd>
<dt><strong>-p</strong> [<em>VAL</em>]</dt>
<dd>
<p>Set Top_p value, nucleus sampling (cmpls/chat, 0.0 - 1.0).</p>
</dd>
<dt><strong>-r</strong> [<em>SEQ</em>]</dt>
<dd>
<p>Set restart sequence string.</p>
</dd>
<dt><strong>-R</strong> [<em>SEQ</em>]</dt>
<dd>
<p>Set start sequence string.</p>
</dd>
<dt><strong>-s</strong> [<em>SEQ</em>]</dt>
<dd>
<p>Set stop sequences, up to 4. Def="<em>&lt;|endoftext|&gt;</em>".</p>
</dd>
<dt><strong>-S</strong> [<em>INSTRUCTION</em>|<em>FILE</em>]</dt>
<dd>
<p>Set an instruction prompt. It may be a text file.</p>
</dd>
<dt><strong>-S</strong> <em>/</em>[<em>PROMPT_NAME</em>]</dt>
<dd>
<p>Set/search prompt from awesome-chatgpt-prompts.</p>
</dd>
<dt><strong>-t</strong> [<em>VAL</em>]</dt>
<dd>
<p>Set temperature value (cmpls/chat/edits/audio), (0.0 - 2.0, whisper
0.0 - 1.0). Def=<em>0</em>.</p>
</dd>
<dt><strong>-u</strong></dt>
<dd>
<p>Copy response to clipboard.</p>
</dd>
<dt><strong>-v</strong></dt>
<dd>
<p>Less verbose.</p>
<p>May set multiple times.</p>
</dd>
<dt><strong>-V</strong></dt>
<dd>
<p>Pretty-print request.</p>
<p>Set twice to dump raw request.</p>
</dd>
<dt><strong>-x</strong></dt>
<dd>
<p>Edit prompt in text editor.</p>
</dd>
<dt><strong>-w</strong> [<em>AUD</em>] [<em>LANG</em>]</dt>
<dd>
<p>Transcribe audio file into text. LANG is optional.</p>
<p>Set twice to get phrase-level timestamps.</p>
</dd>
<dt><strong>-W</strong> [<em>AUD</em>]</dt>
<dd>
<p>Translate audio file into English text.</p>
<p>Set twice to get phrase-level timestamps.</p>
</dd>
<dt><strong>-z</strong></dt>
<dd>
<p>Print last response JSON data.</p>
</dd>
</dl>
</body>
</html>
